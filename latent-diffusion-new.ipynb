{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q diffusers transformers accelerate\n\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom diffusers import AutoencoderKL, UNet2DModel, DDIMScheduler\nfrom accelerate import Accelerator\n\n# ============== 1. Dataset ==============\nclass MangoDataset(Dataset):\n    def __init__(self, root_dir):\n        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir)\n                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n        self.transform = transforms.Compose([\n            transforms.Resize((512, 512)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5]*3, [0.5]*3)\n        ])\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        return self.transform(img)\n\ndata_path = \"/kaggle/input/rganhealthy512x512/HEALTHY\"\ndataset = MangoDataset(data_path)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# ============== 2. Load Models ==============\nvae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\").to(\"cuda\").eval()\nunet = UNet2DModel(\n    sample_size=64,\n    in_channels=4,\n    out_channels=4,\n    layers_per_block=2,\n    block_out_channels=(128, 256, 512, 512),\n    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),\n    up_block_types=(\"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n)\nscheduler = DDIMScheduler(num_train_timesteps=1000)\n\n# ============== 3. Optimizer & Accelerator ==============\noptimizer = torch.optim.AdamW(unet.parameters(), lr=1e-4)\naccelerator = Accelerator()\nunet, optimizer, dataloader = accelerator.prepare(unet, optimizer, dataloader)\n\n# ============== 4. Training ==============\nunet.train()\nnum_epochs = 100\n\nfor epoch in range(1, num_epochs + 1):\n    print(f\"🔥 Epoch {epoch}/{num_epochs}\")\n    for batch in tqdm(dataloader, desc=f\"Epoch {epoch}\"):\n        with torch.no_grad():\n            latents = vae.encode(batch.to(accelerator.device)).latent_dist.sample() * 0.18215\n        noise = torch.randn_like(latents)\n        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (latents.size(0),), device=latents.device).long()\n        noisy_latents = scheduler.add_noise(latents, noise, timesteps)\n\n        noise_pred = unet(noisy_latents, timesteps).sample\n        loss = nn.functional.mse_loss(noise_pred, noise)\n\n        optimizer.zero_grad()\n        accelerator.backward(loss)\n        optimizer.step()\n\n    # ========== Save Sample ==========\n    if epoch % 10 == 0:\n        unet.eval()\n        with torch.no_grad():\n            sample = torch.randn(1, 4, 64, 64).to(accelerator.device)\n            for t in scheduler.timesteps:\n                noise_pred = unet(sample, t).sample\n                sample = scheduler.step(noise_pred, t, sample).prev_sample\n            decoded = vae.decode(sample / 0.18215).sample\n            save_image(decoded, f\"sample_epoch_{epoch}.png\", normalize=True)\n        unet.train()\n\n    # ========== Save Checkpoint ==========\n    if epoch % 10 == 0:\n        unet.save_pretrained(f\"ldm_unet_epoch_{epoch}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T05:29:53.684294Z","iopub.execute_input":"2025-06-19T05:29:53.684775Z","execution_failed":"2025-06-19T09:00:09.950Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"2025-06-19 05:31:20.954447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750311081.197606      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750311081.314131      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"559a09edb2804e8ead920fe208341826"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0774acd387324858b31cc2bdb4d0ed94"}},"metadata":{}},{"name":"stdout","text":"🔥 Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 2988/2988 [30:06<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 2988/2988 [28:23<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 2988/2988 [28:27<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 2988/2988 [28:26<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 2988/2988 [28:29<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  11%|█         | 317/2988 [03:01<25:24,  1.75it/s]","output_type":"stream"}],"execution_count":null}]}