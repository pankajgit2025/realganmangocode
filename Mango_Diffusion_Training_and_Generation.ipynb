{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\uddea Fine-tune DDPM on Mango Leaf Dataset (Kaggle Ready)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install diffusers==0.27.2 transformers accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "from accelerate import Accelerator\n",
        "\n",
        "class MangoLeafDataset(Dataset):\n",
        "    def __init__(self, folder):\n",
        "        self.image_paths = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.png'))]\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(image)\n",
        "\n",
        "# Set path to a class folder\n",
        "dataset_path = \"/kaggle/input/mango-dataset/Anthracnose\"\n",
        "dataset = MangoLeafDataset(dataset_path)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define Model\n",
        "model = UNet2DModel(\n",
        "    sample_size=64, in_channels=3, out_channels=3,\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(64, 128, 128),\n",
        "    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\"),\n",
        "    up_block_types=(\"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n",
        ")\n",
        "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n",
        "\n",
        "# Train\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    for batch in tqdm(dataloader):\n",
        "        noise = torch.randn_like(batch)\n",
        "        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (batch.shape[0],), device=batch.device).long()\n",
        "        noisy_images = scheduler.add_noise(batch, noise, timesteps)\n",
        "        noise_pred = model(noisy_images, timesteps).sample\n",
        "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"/kaggle/working/AnthracnoseDiffusionModel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate 10,000 Images\n",
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "model = UNet2DModel.from_pretrained(\"/kaggle/working/AnthracnoseDiffusionModel\").to(\"cuda\")\n",
        "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "model.eval()\n",
        "os.makedirs(\"/kaggle/working/AnthracnoseGenerated\", exist_ok=True)\n",
        "\n",
        "for i in range(10000):\n",
        "    x = torch.randn((1, 3, 64, 64)).to(\"cuda\")\n",
        "    for t in scheduler.timesteps:\n",
        "        with torch.no_grad():\n",
        "            residual = model(x, t).sample\n",
        "        x = scheduler.step(residual, t, x).prev_sample\n",
        "    save_image(x, f\"/kaggle/working/AnthracnoseGenerated/image_{i:05}.png\", normalize=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}